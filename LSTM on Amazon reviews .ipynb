{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca67230e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90ca4707",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential , Model\n",
    "from keras.layers import Conv2D , MaxPool2D , Dense , Dropout , Flatten\n",
    "from PIL  import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2323795",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.layers import LSTM , SimpleRNN , Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d050249a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f41db99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = pd.read_csv(r\"F:\\Python\\dataset\\amazonreviews.tsv\" , sep = '\\t')  ## file reading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f247f669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pos</td>\n",
       "      <td>Stuning even for the non-gamer: This sound tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pos</td>\n",
       "      <td>The best soundtrack ever to anything.: I'm rea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pos</td>\n",
       "      <td>Amazing!: This soundtrack is my favorite music...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pos</td>\n",
       "      <td>Excellent Soundtrack: I truly like this soundt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pos</td>\n",
       "      <td>Remember, Pull Your Jaw Off The Floor After He...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                             review\n",
       "0   pos  Stuning even for the non-gamer: This sound tra...\n",
       "1   pos  The best soundtrack ever to anything.: I'm rea...\n",
       "2   pos  Amazing!: This soundtrack is my favorite music...\n",
       "3   pos  Excellent Soundtrack: I truly like this soundt...\n",
       "4   pos  Remember, Pull Your Jaw Off The Floor After He..."
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "70fcd6fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 2)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a952e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## so here we are replacing negative and positive with 0 and 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "24ba96d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.label = reviews.label.replace({\"pos\" : 1 , \"neg\" : 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6880b623",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5097\n",
       "1    4903\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "74a5eb0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label     0\n",
       "review    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6aa6d801",
   "metadata": {},
   "outputs": [],
   "source": [
    "## data cleaning done "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c41c52c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_x = reviews.iloc[:: , 1]\n",
    "reviews_y = reviews.iloc[:: , 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d66b479",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dcdfb00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "aa43dad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train , x_test , y_train , y_test = train_test_split(reviews_x , reviews_y , test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7adf2d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000,)\n",
      "(8000,)\n",
      "-----------\n",
      "(2000,)\n",
      "(2000,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(\"-----------\")\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b5de0ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## y into categorical form "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0ad0ed5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0c62064f",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_num_words = 10000  ## so here we are replacing negative and positive with 0 and 1 \n",
    "seq_len = 50 \n",
    "embedding_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17770d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## this max num words will work like sparse matrix so when we have words in that sentence then it will write their 1 else 0\n",
    "## so we will give 10000 limit so till 10000 the columns of one hot encoding will add ( and adding 1 and 0 to respective column)\n",
    "\n",
    "## seq_len = 50 will allow us to have atleast 50 words in our one sentence ( 50 words in one sentence)\n",
    "## and we gave this input to padding so we will get a matrix of 50*50\n",
    "## so when at some point when we dont have any value at that particular position so padding add their 0 \n",
    "## and make this sentence size 50 \n",
    "\n",
    "## embedding_size = 100 \n",
    "## this embedding size will make a vector of that particular word and we gave their 100 so it will make or add 100 values with \n",
    "## respect to their combination of other words \n",
    "## example of embeddings = like gender word is related to boy and girl or queen or king size so for king and queen it will give \n",
    "## the good values because of high relation of words but when we comapre this word to mango and apple so it will not give the \n",
    "## large relational vallues it will give the low values beacuse mango and apple not related with gender \n",
    "## embedding vector representation [0.1 , 1 , 0.005 , -1 , 0.7 , -0.2 , .........................(till 100)] \n",
    "\n",
    "## max_num_words = 10000  ( working on 10000 words with one hot encoding)( working like sparse matrix)( assigning index to word)\n",
    "\n",
    "## seq_len = 50 ( in one sentence allowing atleast 50 words )\n",
    "\n",
    "\n",
    "## embedding_size = 100 ( creating vector with 100 values , and the values of words relation to each other ( gender and fruits))\n",
    "## corelation values added in the vector \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e161befb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_preprocessing.text import Tokenizer\n",
    "from keras_preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "eb405dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=max_num_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e5e03764",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(reviews.review)   ## making 10,000 tokens from the datset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6791b6a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0539da7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = tokenizer.texts_to_sequences(x_train)   ## will convert text to sequence of ids ,converting words in tokens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2d553dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pad_sequences(x_train ,maxlen= seq_len)   ## creating 1 sentence with 50 words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00c91d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## in this we are giving 2 inputs in () because we want to apply padding on x_train data and with sequence of 50 words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ef44be56",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = tokenizer.texts_to_sequences(x_test)  ## will convert text to sequence of ids ,converting words in tokens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "02a7330e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = pad_sequences(x_test , maxlen= seq_len)  ## creating sentence with 50 words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbad128",
   "metadata": {},
   "outputs": [],
   "source": [
    "## in this we are giving 2 inputs in () because we want to apply padding on x_test data and with sequence of 50 words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79a16c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## with this two syntax we will convert our text in the numeric format so we will able to build the algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ab1a9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a1baa417",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential() ## intialising the model \n",
    "\n",
    "model.add(Embedding( input_dim = max_num_words , input_length = seq_len , output_dim = embedding_size  ))\n",
    "## giving input as max num words and lenghth of 50 words which is stored in seq_len and output_dim as embedding size vector\n",
    "\n",
    "model.add(LSTM(5))\n",
    "## adding layer of long short term memory \n",
    "## LSTM(5) ## this 5 is the number of neuron in our single LSTM layer \n",
    "\n",
    "model.add(Dense(2 , activation = 'softmax'))\n",
    "## output layer\n",
    "## there are 2 output classes ham and spam which is denoted by 0 and 1 so in output layer layer we are giving 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "35c9ba1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer= \"adam\" , loss = \"categorical_crossentropy\" , metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b3d4e138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 0.0078 - accuracy: 0.9984 - val_loss: 0.9787 - val_accuracy: 0.7756\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - 6s 29ms/step - loss: 0.0451 - accuracy: 0.9856 - val_loss: 0.9315 - val_accuracy: 0.7969\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - 6s 31ms/step - loss: 0.0273 - accuracy: 0.9920 - val_loss: 0.8397 - val_accuracy: 0.7912\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - 6s 30ms/step - loss: 0.0137 - accuracy: 0.9964 - val_loss: 0.9365 - val_accuracy: 0.7906\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - 6s 29ms/step - loss: 0.0045 - accuracy: 0.9997 - val_loss: 1.0036 - val_accuracy: 0.7975\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26d0b380130>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train , y_train , epochs= 5 , batch_size = 32, validation_split= .2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e505b247",
   "metadata": {},
   "outputs": [],
   "source": [
    "## model fitting done and its time fopr prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "41603ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e54d58ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.5249641e-01, 4.7503594e-02],\n",
       "       [9.9319780e-01, 6.8021882e-03],\n",
       "       [6.3709100e-04, 9.9936289e-01],\n",
       "       ...,\n",
       "       [2.0623421e-03, 9.9793768e-01],\n",
       "       [2.7346537e-03, 9.9726534e-01],\n",
       "       [9.9925381e-01, 7.4622099e-04]], dtype=float32)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7c69eaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_classes = np.argmax(pred , 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4ce3b13c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 1, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2ae33267",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix , accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "577ccba6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[759, 247],\n",
       "       [204, 790]], dtype=int64)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tab1 = confusion_matrix(y_test , pred_classes)\n",
    "tab1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1743b463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77.45"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test , pred_classes)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cea3a67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cc0518",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18723e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a161b56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
